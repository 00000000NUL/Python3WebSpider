# Scrapy集成Selenium

首先新建项目，命令如下：

```
scrapy startproject scrapyseleniumtest
```

新建一个Spider，命令如下：

```
scrapy genspider taobao www.taobao.com
```

```python
ROBOTSTXT_OBEY = False
```

```python
import scrapy

class TaobaoSpider(scrapy.Spider):
    name = 'taobao'
    allowed_domains = ['www.taobao.com']
    start_urls = ['https://s.taobao.com/search?q=ipad']

    def parse(self, response):
        print(response.css('.m-itemlist .items .item'))
```

```
scrapy crawl taobao
```

```python

from selenium import webdriver
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from scrapy.http import HtmlResponse
from logging import getLogger

class SeleniumMiddleware():
    def __init__(self):
        self.logger = getLogger(__name__)
    
    def process_request(self, request, spider):
        self.logger.debug('PhantomJS is Starting')
        browser = webdriver.PhantomJS()
        browser.set_window_size(1400, 700)
        try:
            browser.get(request.url)
            WebDriverWait(browser, 30).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.m-itemlist .items .item')))
            return HtmlResponse(url=request.url, body=browser.page_source, request=request, encoding='utf-8',
                                status=200)
        except TimeoutException:
            return HtmlResponse(url=request.url, status=500, request=request)
        finally:
            browser.close()
```