# 11.6 Appium+MitmDump爬取京东商品

在前文中我们曾经用 Charles 分析过京东商品的评论数据，但是可以发现其参数相当复杂，在 Form 表单中有很多加密参数，如果我们单单只用 Charles 探测到了这个接口链接和参数还是无法构造直接构造这个 Request 的参数，这里面涉及到一些加密算法，所以我们也就无法直接还原这个抓取过程。

所以在后面我们又了解了 MitmProxy 的用法，利用它的 MitmDump 组件我们可以直接对接 Python 脚本对抓取的数据包进行处理，将 Request 和 Response 直接用 Python脚本进行处理，利用它我们自然就可以绕过 Request的参数构造过程，直接监听 Response 进行处理即可，但是这个过程并不是自动化的，在前面抓取得到 APP 的时候实际上是人工模拟了这个拖动过程，如果这个操作可以用程序来实现就更好了。

所以接下来我们又了解了 Appium 的用法，它可以指定自动化脚本模拟实现 APP 的一系列动作，如点击、拖动等等动作，同时它也可以提取 APP 中呈现的信息，但是经过上节爬取微信朋友圈的实例我们可以知道这个解析过程还是比较繁琐的，而且速度需要加以限制，如果内容没有显示出来解析就会失败，而且还会导致重复提取的问题，更重要的是它只可以获取在 APP 中看到的信息，无法直接提取接口获取的真实数据，但是接口的数据往往是最易提取且信息量最全的，所以最恰当的提取来源就是提取原始接口的返回数据。

综合以上几点，我们就可以确定出一个解决方案了，如果我们用 MitmDump 去监听接口数据，用 Appium 去模拟 APP 的操作，那不就可以既绕过复杂的接口参数又可以实现自动化抓取了？这种方式可以称作是抓取 APP 数据的最佳方式，但是某些特殊情况除外，如微信朋友圈数据又经过了一次加密无法解析，只能用 Appium 提取，但是对于大多数 APP 来说，此种方法是奏效的，本节我们就来用一个实例感受一下这种抓取方式的便捷之处。

### 1. 本节目标

本节我们以抓取京东 APP 的商品信息和评论为例，实现一下 Appium 和 MitmDump 二者结合的抓取。抓取的数据分为两部分，一部分是商品信息，需要获取商品的 ID、名称和图片，组成一条商品数据，另一部分是商品的评论信息，将评论人的昵称、评论正文、评论日期、发表图片都提取下来，然后加入商品 ID 字段，组成一条评论数据。最后将数据保存到 MongoDB 数据库。

### 2. 准备工作

在本节开始之前请确保 PC 上已经安装好了 Charles、MitmDump 和 MitmDump、Appium、Android 开发环境和Python 版本的 Appium API，还需要在 Android 手机上安装好京东 APP，另外还需要安装好 MongoDB 并运行其服务，还需要安装 PyMongo 库，具体的配置过程可以参考第一章。

### 3. Charles抓包分析

首先在开始之前我们将手机代理设置到 Charles 上面，用 Charles 抓包分析一下获取商品详情和商品评论的接口。

首先是获取商品详情的接口，这里提取到的接口是来自  cdnware.m.jd.com 的链接，返回结果是一个 Json 字符串，里面包含了商品的 ID 和商品名称，如图 11-47 和 11-48 所示：

![](./assets/11-47.jpg)

图 11-47 请求概览

![](./assets/11-48.jpg)

图 11-48 响应结果

接下来我们再获取商品评论的接口，这个过程我们在前文也提到过了，在此不再赘述，是来自 api.m.jd.com 的接口，返回结果也是 Json 字符串，里面包含了商品的数条评论信息。

分析好了接口之后我们就可以用 MitmDump 对接一个 Python 脚本来实现数据的抓取了。

### 4. MitmDump抓取

接下来我们首先新建一个脚本文件，然后实现这个脚本以提取这两个接口的数据，首先我们提取一下商品的信息，代码如下：

```python
def response(flow):
    url = 'cdnware.m.jd.com'
    if url in flow.request.url:
        text = flow.response.text
        data = json.loads(text)
        if data.get('wareInfo') and data.get('wareInfo').get('basicInfo'):
            info = data.get('wareInfo').get('basicInfo')
            id = info.get('wareId')
            name = info.get('name')
            images = info.get('wareImage')
            print(id, name, images)
```

首先声明了接口的部分链接内容，然后与 Request 的 URL 作比较，如果出现在当前的 URL 中，那就证明当前的 Respons e就是商品详情的 Response，然后我们提取对应的 Json 信息即可，在这里我们将商品的 ID、名称和图片提取了出来，这就是一条商品数据。

接下来我们再提取一下评论的数据，代码实现如下：

```python
# 提取评论数据
url = 'api.m.jd.com/client.action'
if url in flow.request.url:
    pattern = re.compile('sku\".*?\"(\d+)\"')
    # Request请求参数中包含商品ID
    body = unquote(flow.request.text)
    # 提取商品ID
    id = re.search(pattern, body).group(1) if re.search(pattern, body) else None
    # 提取Response Body
    text = flow.response.text
    data = json.loads(text)
    comments = data.get('commentInfoList') or []
    # 提取评论数据
    for comment in comments:
        if comment.get('commentInfo') and comment.get('commentInfo').get('commentData'):
            info = comment.get('commentInfo')
            text = info.get('commentData')
            date = info.get('commentDate')
            nickname = info.get('userNickName')
            pictures = info.get('pictureInfoList')
            print(id, nickname, text, date, pictures)
```

这里我们还是指定了接口的部分链接内容用以判断当前 Request 的 URL 是不是获取评论的 URL，如果满足条件，那么就提取商品的 ID 和评论信息。

商品的 ID 实际上是隐藏在 Request 中，我们需要提取 Request 的表单内容提取商品的 ID，这里直接用了正则表达式提取。

商品的评论信息是在 Response 中，所以在这里我们还是像刚才一样提取了 Response 的内容，然后对 Json 进行解析，最后提取出来了商品评论人的昵称、评论正文、评论日期和图片信息，然后再和商品的 ID 组合起来，形成一条评论数据。

最后我们用 MongoDB 将两部分数据分开保存到两个 Collection 即可，在此不再赘述。

运行此脚本，命令如下：

```
mitmdump -s script.py
```

这时将手机的代理设置到 MitmDump 上，我们在京东 APP中打开某个商品，然后再打开商品评论部分，下拉即可看到控制台输出了两部分的抓取结果，并成功保存到了 MongoDB 数据库，如图 11-49 所示：

![](./assets/11-49.jpg)

图 11-49 保存结果

现在如果我们手动操作京东 APP 就可以做到京东商品评论的抓取了，下一步我们要做的就是实现自动滚动刷新。

### 5. Appium自动化

接下来我们再将 Appium 对接到手机上，用 Appium 驱动 APP 完成一系列动作，进入 APP 后我们需要做的操作有点击搜索框、输入搜索的商品名称、点击进入商品详情、进入评论页面、自动滚动刷新，基本的操作逻辑和爬取微信朋友圈的相同。

这里京东 APP 的 Desired Capabilities 配置如下：

```python
{
    'platformName': 'Android',
    'deviceName': 'MI_NOTE_Pro',
    'appPackage': 'com.jingdong.app.mall',
    'appActivity': 'main.MainActivity'
}
```

接下来我们可以首先用 Appium 内置的驱动打开京东 APP，如图 11-50 所示：

![](./assets/11-50.jpg)

图 11-50 调试界面

然后在这里进行一系动作操作并录制下来，同时找到各个页面的组件的 ID 并做好记录，最后再改写成完整的代码。

参考代码实现如下：

```python
from appium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from time import sleep

class Action():
    def __init__(self):
        # 驱动配置
        self.desired_caps = {
            'platformName': PLATFORM,
            'deviceName': DEVICE_NAME,
            'appPackage': 'com.jingdong.app.mall',
            'appActivity': 'main.MainActivity'
        }
        self.driver = webdriver.Remote(DRIVER_SERVER, self.desired_caps)
        self.wait = WebDriverWait(self.driver, TIMEOUT)
    
    def comments(self):
        # 点击进入搜索页面
        search = self.wait.until(EC.presence_of_element_located((By.ID, 'com.jingdong.app.mall:id/mp')))
        search.click()
        # 输入搜索文本
        box = self.wait.until(EC.presence_of_element_located((By.ID, 'com.jd.lib.search:id/search_box_layout')))
        box.set_text(KEYWORD)
        # 点击搜索按钮
        button = self.wait.until(EC.presence_of_element_located((By.ID, 'com.jd.lib.search:id/search_btn')))
        button.click()
        # 点击进入商品详情
        view = self.wait.until(EC.presence_of_element_located((By.ID, 'com.jd.lib.search:id/product_list_item')))
        view.click()
        # 进入评论详情
        tab = self.wait.until(EC.presence_of_element_located((By.ID, 'com.jd.lib.productdetail:id/pd_tab3')))
        tab.click()
    
    def scroll(self):
        while True:
            # 模拟拖动
            self.driver.swipe(FLICK_START_X, FLICK_START_Y + FLICK_DISTANCE, FLICK_START_X, FLICK_START_Y)
            sleep(SCROLL_SLEEP_TIME)
    
    def main(self):
        self.comments()
        self.scroll()

if __name__ == '__main__':
    action = Action()
    action.main()
```

实现比较简单，逻辑与上一节微信朋友圈的抓取类似。注意由于 APP 可能由于版本更新的原因，交互流程和元素 ID 可能有所更改，在这里代码仅做参考，以实际 APP 为准。

可以注意到在下拉的过程中已经省去了用 Appium 提取数据的过程，因为这个过程我们已经用 MitmDump 来帮助我们实现了。

运行之后便会启动京东 APP，然后进入到商品的详情页，然后进入到评论页再无限滚动，这样就代替了我们人工操作，Appium 一边实现模拟滚动，MitmDump 一边进行抓取，这样 APP 的数据就会保存到数据库中了。

### 6. 本节代码

本节代码地址：[https://github.com/Python3WebSpider/MitmAppiumJD](https://github.com/Python3WebSpider/MitmAppiumJD)。


### 7. 结语

以上便是 Appium 和 MitmDump 抓取京东 APP 数据的过程，有了两者的配合，我们既可以做到实时数据处理又可以实现自动化爬取，这样就可以做到绝大多数 APP 的爬取了。


