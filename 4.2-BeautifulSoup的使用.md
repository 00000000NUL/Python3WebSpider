## BeautifulSoup的使用

前面我们介绍了正则表达式的相关用法，但是一旦正则写的有问题，可能得到的就不是我们想要的结果了，而且对于一个网页来说，都有一定的特殊的结构和层级关系，而且很多标签都有id或class来对作区分，所以我们借助于它们的结构和属性来提取不也是可以的吗？

所以，这一节我们就介绍一个强大的解析工具，叫做BeautiSoup，它就是借助网页的结构和属性等特性来解析网页的工具，有了它我们不用再去写一些复杂的正则，只需要简单的几条语句就可以完成网页中某个元素的提取。

废话不多说，接下来我们就来感受一下BeautifulSoup的强大之处吧。

### BeautifulSoup简介

简单来说，BeautifulSoup就是Python的一个HTML或XML的解析库，我们可以用它来方便地从网页中提取数据，官方的解释如下：

> BeautifulSoup提供一些简单的、python式的函数用来处理导航、搜索、修改分析树等功能。它是一个工具箱，通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完整的应用程序。
BeautifulSoup自动将输入文档转换为Unicode编码，输出文档转换为utf-8编码。你不需要考虑编码方式，除非文档没有指定一个编码方式，这时你仅仅需要说明一下原始编码方式就可以了。
BeautifulSoup已成为和lxml、html6lib一样出色的python解释器，为用户灵活地提供不同的解析策略或强劲的速度。

所以说，利用它我们可以省去很多繁琐的提取工作，提高解析效率。

### 安装

使用之前，我们当然需要首先说明一下它的安装方式。目前BeautifulSoup的最新版本是4.x版本，之前的版本已经停止开发了，推荐使用pip来安装，安装命令如下：

```
pip3 install beautifulsoup4
```

当然也可以从pypi下载whl文件安装，链接如下：

[https://pypi.python.org/pypi/beautifulsoup4](https://pypi.python.org/pypi/beautifulsoup4)

好，安装完成之后可以验证一下，写一段Python程序试验一下。

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup('<p>Hello</p>', 'html.parser')
print(soup.p.string)
```

运行结果

```
Hello
```

如果没有报错，则证明安装没有问题，关于它的解析用法我们在后面会详细介绍。

> 注意在这里我们虽然安装的是beautifulsoup4这个包，但是在引入的时候是引入的bs4，这是因为这个包源代码本身的库文件夹名称就是bs4，所以安装完成之后，这个库文件夹就被移入到我们本机Python3的lib库里，所以识别到的库文件名称就叫做bs4，所以我们引入的时候就引入bs4这个包。
因此，包本身的名称和我们使用时导入的包的名称并不一定是一致的。

### 解析器

BeautifulSoup在解析的时候实际上是依赖于解析器的，它除了支持Python标准库中的HTML解析器，还支持一些第三方的解析器比如lxml，下面我们对BeautifulSoup支持的解析器及它们的一些优缺点做一个简单的对比。

|  解析器	| 使用方法 | 优势 | 劣势 |
|----- | ----- | ----- | ----- |
| Python标准库 |	BeautifulSoup(markup, "html.parser")	| Python的内置标准库、执行速度适中 、文档容错能力强 | Python 2.7.3 or 3.2.2)前的版本中文容错能力差|
| lxml HTML 解析器	| BeautifulSoup(markup, "lxml")	| 速度快、文档容错能力强 | 需要安装C语言库 |
| lxml XML 解析器	| BeautifulSoup(markup, "xml") | 速度快、唯一支持XML的解析器 | 需要安装C语言库 |
| html5lib	| BeautifulSoup(markup, "html5lib")	 | 最好的容错性、以浏览器的方式解析文档、生成HTML5格式的文档 | 速度慢、不依赖外部扩展 |

所以通过以上对比可以看出，lxml这个解析器有解析HTML和XML的功能，而且速度快，容错能力强，所以推荐使用这个库来进行解析，但是这里的劣势是必须安装一个C语言库，它叫做lxml，我们在这里依然使用pip安装即可，命令如下：

```
pip3 install lxml
```

安装完成之后，我们就可以使用lxml这个解析器来解析了，在初始化的时候我们可以把第二个参数改为lxml，如下：

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup('<p>Hello</p>', 'lxml')
print(soup.p.string)
```

运行结果是完全一致的，后面BeautifulSoup的用法实例也统一用这个库来演示。

### 基本使用

下面我们首先用一个实例来感受一下BeautifulSoup的基本使用：

```python
html = """
<html><head><title>The Dormouse's story</title></head>
<body>
<p class="title" name="dromouse"><b>The Dormouse's story</b></p>
<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1"><!-- Elsie --></a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>
<p class="story">...</p>
"""
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, 'lxml')
print(soup.prettify())
print(soup.title.string)
```

运行结果：

```html
<html>
 <head>
  <title>
   The Dormouse's story
  </title>
 </head>
 <body>
  <p class="title" name="dromouse">
   <b>
    The Dormouse's story
   </b>
  </p>
  <p class="story">
   Once upon a time there were three little sisters; and their names were
   <a class="sister" href="http://example.com/elsie" id="link1">
    <!-- Elsie -->
   </a>
   ,
   <a class="sister" href="http://example.com/lacie" id="link2">
    Lacie
   </a>
   and
   <a class="sister" href="http://example.com/tillie" id="link3">
    Tillie
   </a>
   ;
and they lived at the bottom of a well.
  </p>
  <p class="story">
   ...
  </p>
 </body>
</html>
The Dormouse's story
```

首先我们声明了一个变量html，它是一个HTML字符串，但是注意到，它并不是一个完整的HTML字符串，`<body>`和`<html>`标签都没有闭合，但是我们将它当作第一个参数传给BeautifulSoup对象，第二个参数传入的是解析器的类型，在这里我们使用lxml，这样就完成了BeaufulSoup对象的初始化，将它赋值给soup这个变量。

那么接下来我们就可以通过调用soup的各个方法和属性对这串HTML代码解析了。

我们首先调用了prettify()方法，这个方法可以把要解析的字符串以标准的缩进格式输出，在这里注意到输出结果里面包含了`</body>`和`</html>`标签，也就是说对于不标准的HTML字符串BeautifulSoup可以自动更正格式，这一步实际上不是由prettify()方法做的，这个更正实际上在初始化BeautifulSoup时就完成了。

然后我们调用了`soup.title.string`，这个实际上是输出了HTML中`<title>`标签的文本内容。所以`soup.title`就可以选择出HTML中的`<title>`标签，再调用string属性就可以得到里面的文本了，所以我们就可以通过简单地调用几个属性就可以完成文本的提取了，是不是非常方便？

## 标签选择器

刚才我们选择元素的时候直接通过调用标签的名称就可以选择标签元素了，然后再调用string属性就可以得到标签内的文本了，这种选择方式速度非常快，如果单个标签结构话层次非常清晰，可以选用这种方式来解析。

### 选择元素

下面我们再用一个例子详细说明一下它的选择方法。

```python
html = """
<html><head><title>The Dormouse's story</title></head>
<body>
<p class="title" name="dromouse"><b>The Dormouse's story</b></p>
<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1"><!-- Elsie --></a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>
<p class="story">...</p>
"""
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, 'lxml')
print(soup.title)
print(type(soup.title))
print(soup.title.string)
print(soup.head)
print(soup.p)
```

运行结果：

```html
<title>The Dormouse's story</title>
<class 'bs4.element.Tag'>
The Dormouse's story
<head><title>The Dormouse's story</title></head>
<p class="title" name="dromouse"><b>The Dormouse's story</b></p>
```

在这里我们依然选用了刚才的HTML代码，我们首先打印输出了title标签的选择结果，输出结果正是title标签加里面的文字内容。接下来输出了它的类型，是`bs4.element.Tag`类型，这是BeautifulSoup中的一个重要的数据结构，经过选择器选择之后，选择结果都是这种Tag类型，它具有一些属性比如string属性，调用Tag的string属性，就可以得到节点的文本内容了，所以接下来的输出结果正是节点的文本内容。

接下来我们又尝试选择了head标签，结果也是标签加其内部的所有内容，再接下来选择了p标签，不过这次情况比较特殊，我们发现结果是第一个p标签的内容，后面的几个p标签并没有选择到，也就是说，当有多个标签时，这种选择方式只会选择到第一个匹配的标签，其他的后面的标签都会忽略。

### 提取信息

在上面我们演示了调用string属性来获取文本的值，那我们要获取标签属性值怎么办呢？获取标签名怎么办呢？下面我们来统一梳理一下信息的提取方式

#### 获取名称

可以利用name属性来获取标签的名称。还是以上面的文本为例，我们选取title标签，然后调用name属性就可以得到标签名称。

```python
print(soup.title.name)
```

运行结果:

```
title
```

#### 获取属性

每个标签可能有多个属性，比如id，class等等，我们选择到这个标签元素之后，可以调用attrs获取所有属性。

```python
print(soup.p.attrs)
print(soup.p.attrs['name'])
```

运行结果：

```python
{'class': ['title'], 'name': 'dromouse'}
dromouse
```

可以看到attrs的返回结果是字典形式，把选择的标签的所有属性和属性值组合成一个字典，接下来如果要获取name属性，就相当于从字典中获取某个键值，只需要用中括号加属性名称就可以得到结果了，比如获取name属性就可以通过`attrs['name']`得到相应的属性值。

其实这样的写法还有点繁琐，还有一种更简单的获取方式，我们可以不用写attrs，直接标签元素后面加中括号，传入属性名就可以达到属性值了，样例如下：

```python
print(soup.p['name'])
print(soup.p['class'])
```

运行结果：

```
dromouse
['title']
```

在这里注意到有的返回结果是字符串，有的返回结果是字符串组成的列表。比如name属性的值是唯一的，返回的结果就是单个字符串，而对于class，一个标签元素可能由多个class，所以返回的是列表，所以在实际处理过程中要注意判断类型。

#### 获取内容

可以利用string属性获取标签元素包含的文本内容，比如上面的文本我们获取第一个p标签的文本：

```python
print(soup.p.string)
```

运行结果：

```
The Dormouse's story
```

再次注意一下这里选择到的p标签是第一个p标签，获取的文本也就是第一个p标签里面的文本。

### 关联选择

我们在做选择的时候有时候不能做到一步就可以选择到想要的标签元素，有时候在选择的时候需要先选中某一个标签元素，然后以它为基准再选择它的子节点、父节点、兄弟节点等等。所以在这里我们就介绍下如何来选择这些标签元素。

#### 嵌套选择

在上面的例子中我们知道每一个返回结果都是`bs4.element.Tag`类型，它同样可以继续调用标签进行下一步的选择，比如我们获取了head标签元素，我们可以继续调用head来选取其内部的head标签元素。

```python
html = """
<html><head><title>The Dormouse's story</title></head>
<body>
"""
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, 'lxml')
print(soup.head.title)
print(type(soup.head.title))
print(soup.head.title.string)
```

运行结果：

```
<title>The Dormouse's story</title>
<class 'bs4.element.Tag'>
The Dormouse's story
```

第一行结果是我们调用了head之后再次调用了title来选择的title标签元素，然后我们紧接着打印输出了它的类型，可以看到它仍然是`bs4.element.Tag`类型，也就是说我们在Tag类型的基础上再次选择得到的依然还是Tag类型，每次返回的结果都相同，所以这样我们就可以这样做嵌套的选择了。

最后输出了一下它的string属性，也就是标签里的文本内容。

#### 子节点和子孙节点

选取到了一个标签元素之后，如果想要获取它的直接子节点可以调用contents属性，我们用一个实例来感受一下：

```python
html = """
<html>
    <head>
        <title>The Dormouse's story</title>
    </head>
    <body>
        <p class="story">
            Once upon a time there were three little sisters; and their names were
            <a href="http://example.com/elsie" class="sister" id="link1">
                <span>Elsie</span>
            </a>
            <a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> 
            and
            <a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>
            and they lived at the bottom of a well.
        </p>
        <p class="story">...</p>
"""
```

运行结果：

```python
['\n            Once upon a time there were three little sisters; and their names were\n            ', <a class="sister" href="http://example.com/elsie" id="link1">
<span>Elsie</span>
</a>, '\n', <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>, ' \n            and\n            ', <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>, '\n            and they lived at the bottom of a well.\n        ']
```

返回的结果是列表形式，p标签里面既包含文本，又包含标签，返回的结果会将他们以列表形式都统一返回。

注意得到的列表的每一个元素都是p标签的直接子节点，比如第一个a标签里面包含了一层span标签，这个就相当于孙子节点了，但是返回结果中并没有单独把span标签选出来作为结果的一部分，所以说contents属性得到的结果是直接子节点的列表。

同样地我们可以调用children属性，得到相应的结果。

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, 'lxml')
print(soup.p.children)
for i, child in enumerate(soup.p.children):
    print(i, child)
```

运行结果：

```
<list_iterator object at 0x1064f7dd8>
0 
            Once upon a time there were three little sisters; and their names were
            
1 <a class="sister" href="http://example.com/elsie" id="link1">
<span>Elsie</span>
</a>
2 

3 <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>
4  
            and
            
5 <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>
6 
            and they lived at the bottom of a well.
```

还是同样的HTML文本，在这里我们调用了children属性来进行选择，返回结果可以看到是生成器类型，所以接下来我们用for循环输出了一下相应的内容，内容其实是一样的，只不过children返回的是生成器类型，而contents返回的是列表类型。

如果我们要得到所有的子孙节点的话可以调用descendants属性。

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, 'lxml')
print(soup.p.descendants)
for i, child in enumerate(soup.p.descendants):
    print(i, child)
```

运行结果：

```
<generator object descendants at 0x10650e678>
0 
            Once upon a time there were three little sisters; and their names were
            
1 <a class="sister" href="http://example.com/elsie" id="link1">
<span>Elsie</span>
</a>
2 

3 <span>Elsie</span>
4 Elsie
5 

6 

7 <a class="sister" href="http://example.com/lacie" id="link2">Lacie</a>
8 Lacie
9  
            and
            
10 <a class="sister" href="http://example.com/tillie" id="link3">Tillie</a>
11 Tillie
12 
            and they lived at the bottom of a well.
```

返回结果还是生成器，遍历输出一下可以看到这次的输出结果就包含了span标签，descendants会递归地查询所有子节点，得到的是所有的子孙节点。


