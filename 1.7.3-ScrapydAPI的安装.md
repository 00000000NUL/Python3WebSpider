# ScrapydAPI的安装

安装好了Scrapyd之后，我们可以直接请求它提供的API即可获取当前主机的Scrapy任务运行状况。

如某台主机的IP为192.168.1.1，则可以直接运行如下命令获取当前主机的所有Scrapy项目：

```
curl http://localhost:6800/listprojects.json
```

运行结果：

```
{"status": "ok", "projects": ["myproject", "otherproject"]}
```

返回结果是Json字符串，通过解析这个字符串我们便可以得到当前主机所有项目。

但是用这种方式来获取任务状态还是有点繁琐，所以ScrapydAPI就为它做了一层封装，下面我们来看下它的安装方式。

## Pip安装

推荐使用Pip，也是最简单的安装方式：

```
pip install python-scrapyd-api
```

## 测试安装

安装完成之后便可以使用Python来获取主机状态了，所以如上的操作便可以用Python代码实现：

```python
from scrapyd_api import ScrapydAPI
scrapyd = ScrapydAPI('http://localhost:6800')
print(scrapyd.list_projects())
```

运行结果：

```python
["myproject", "otherproject"]
```

这样我们便可以用Python直接来获取各个主机上Scrapy任务的运行状态了。


