## 2.1 HTTP基本原理

在本节我们会详细了解HTTP的基本原理，了解在浏览器中敲入一个URL到获取网页内容发生了一个怎样的过程，了解了这些内容，有助于去进一步了解爬虫的基本原理。

### 1. URI、URL

在了解HTTP之前我们先了解一下URI和URL。我们经常会听到URI和URL两个术语，URI全称为Uniform Resource Identifier，即统一资源标志符，URL全称为Universal Resource Locator，即统一资源定位符。

举例来说，[https://github.com/favicon.ico](https://github.com/favicon.ico)，这是GitHub的网站图标链接，它是一个URL，也是一个URI，即有这样的一个图标资源，我们用URL/URI来唯一指定了它的访问方式，这其中包括了访问协议https、访问路径/即根目录，资源名称favicon.ico，通过这样的一个链接我们便可以从互联网上找到这个资源，这就是URL/URI。

URL是URI的子集，也就是说每个URL都是URI，但不是每个URI都是URL。那么怎样的URI不是URL呢？URI还包括一个子类叫做URN，它的全称为Universal Resource Name，即统一资源名称。URN只命名资源而不指定如何定位资源，如urn:isbn:0451450523，它指定了一本书的ISBN，可以唯一标识这一本书，但是没有指定到哪里定位这本书，这就是URN，URL、URN、URI的关系可以用图表示如下：

![](./assets/2017-08-19-21-33-17.jpg)

但是在目前的互联网，URN的使用非常少，所以几乎所有的URI都是URL，所以一般的网页链接我们可以称之为URL，也可以称之为URI，我个人习惯称之为URL。

### 2. 超文本

接下来我们再了解一个概念，超文本。超文本英文名称叫做Hypertext，我们在浏览器里面看到的网页就是超文本解析而成的，其网页源代码是一系列HTML代码，里面包含了一系列标签，如 img 显示图片，p 指定显示段落等，浏览器解析这些标签后便形成了我们平常看到的网页，而这网页的源代码HTML就可以称作超文本。

例如我们在Chrome浏览器里面打开任意一个页面，如淘宝首页，右键点击检查，或按下快捷键F12即可打开浏览器的开发者工具，这时我们在Elements选项卡即可看到当前网页的源代码，这些源代码都是超文本，如图所示：

![](./assets/2017-08-19-21-38-08.png)


### 3. HTTP、HTTPS

我们在前面了解了URI和URL，例如淘宝的首页：[https://www.taobao.com/](https://www.taobao.com/)，在URL的开头会有http或https，这个就是访问资源需要的协议类型，有时我们还会看到ftp、sftp、smb开头的URL，那么这里的ftp、sftp、smb都是指的协议类型。在爬虫中，我们抓取的页面通常就是http或https协议的，我们在这里首先来了解一下这两个协议的含义。

HTTP的全称是Hyper Text Transfer Protocol，中文名叫做超文本传输协议，HTTP协议是用于从网络传输超文本数据到本地浏览器的传送协议，它能保证传送高效而准确地传送超文本文档。HTTP由万维网协会（World Wide Web Consortium）和Internet工作小组IETF（Internet Engineering Task Force）共同合作制定的规范，目前广泛使用的是HTTP 1.1版本。

HTTPS的全称是Hyper Text Transfer Protocol over Secure Socket Layer，是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，简称为HTTPS。

HTTPS的安全基础是SSL，因此通过它传输的内容都是经过SSL加密的，它的主要作用可以分为两种：
* 是建立一个信息安全通道，来保证数据传输的安全。
* 确认网站的真实性，凡是使用了 https 的网站，都可以通过点击浏览器地址栏的锁头标志来查看网站认证之后的真实信息，也可以通过 CA 机构颁发的安全签章来查询。

现在越来越多的网站和APP都已经向HTTPS方向发展。例如：
* 苹果公司强制所有iOS App在2017年1月1日前全部改为使用HTTPS加密，否则APP就无法在应用商店上架。
* 谷歌从2017年1月推出的Chrome 56开始，对未进行HTTPS加密的网址链接亮出风险提示，即在地址栏的显著位置提醒用户“此网页不安全”。
* 腾讯微信小程序的官方需求文档要求后台使用HTTPS请求进行网络通信，不满足条件的域名和协议无法请求。

而某些网站虽然使用了HTTPS协议还是会被浏览器提示不安全，例如我们在Chrome浏览器里面打开12306，链接为[https://www.12306.cn/](https://www.12306.cn/)，这时浏览器就会提示“您的连接不是私密连接”这样的话，如图所示：

![](./assets/2017-08-19-21-57-30.png)

这是因为12306的CA证书的CA是中国铁道部自己颁发给自己的，而这个证书是不被官方机构认可的，所以这里证书验证就不会通过而提示这样的话，但是实际上它的数据传输依然是经过SSL加密的。我们如果要爬取这样的站点就需要设置忽略证书的选项，否则会提示SSL链接错误，在后文会进行详细说明。

### 4. HTTP请求过程

我们在浏览器中输入一个URL，回车之后便会在浏览器中观察到页面内容，实际上这个过程是浏览器向网站所在的服务器发送了一个Request，即请求，网站服务器接收到这个Request之后进行处理和解析，然后返回对应的一个Response，即响应，然后传回给浏览器，Response里面就包含了页面的源代码等内容，浏览器再对其进行解析便将网页呈现了出来，模型如图所示：

![](./assets/2017-08-19-22-35-20.jpg)

此处客户端即代表我们自己的PC或手机浏览器，服务器即要访问的网站所在的服务器。

为了更直观地地说明这个的过程，我们在这里用Chrome浏览器的开发者模式下的Network监听组件来做下演示，它可以显示访问当前请求网页时发生的所有网络请求和响应。

打开Chrome浏览器，右键点击检查，或按下快捷键F12即可打开浏览器的开发者工具，我们在这里访问百度：[http://www.baidu.com/](http://www.baidu.com/)，输入该URL，敲击回车访问这个页面，观察一下在这个过程中发生了怎样的网络请求，这时我们可以看到在Network页面的下方出现了一个个的条目，那么这一个条目就代表一次发送Request和接收Response的过程，如图所示：

![](./assets/2017-06-08-02-07-05.png)

我们观察第一个网络请求，即www.baidu.com。

![](./assets/2017-06-07-23-02-55.jpg)

这一个条目的各列分别代表：
* 第一列Name，即Request的名称。一般会用URL的最后一部分内容当做名称。
* 第二列Status，即Response的状态码。这里显示为200，代表Response是正常的，通过状态码我们可以判断发送了Request之后是否得到了正常的Response。
* 第三列Type，即Request请求的文档类型。这里为document，代表我们这次请求的是一个HTML文档，内容就是一些HTML代码。
* 第四列Initiator，即请求源。用来标记Request是由哪个对象或进程发起的。
* 第五列Size，即从服务器下载的文件和请求的资源大小。如果是从缓存中取得的资源则该列会显示 from cache。
* 第六列Time，即发起Request到获取到Response所用的总时间。
* 第七列Timeline，即网络请求的可视化瀑布流。

我们点击这个条目即可看到其更详细的信息，如图所示：

![](./assets/2017-06-07-23-05-55.jpg)

首先是General部分，Request URL为Request的URL，Request Method为请求的方法，Status Code为响应状态码，Remote Address为远程服务器的地址和端口，Referrer Policy为Referrer判别策略。

再继续往下看可以看到有一个Response Headers和一个Request Headers，这分别代表响应头和请求头，请求头里面带有许多请求信息，例如浏览器标识、Cookies、Host等信息，这是Request的一部分，服务器会根据请求头内的信息判断请求是否合法，进而作出对应的响应，返回Response，那么在图中看到的Response Headers就是Response的一部分，例如其中包含了服务器的类型、文档类型、日期等信息，浏览器接受到Response后，会解析响应内容，进而呈现网页内容。

下面我们分别来介绍一下请求Request和响应Response都包含了哪些内容，在这里进行对其组成进行总结：

### 5. Request

Request，即请求，由客户端向服务端发出。可以将Request划分为四部分内容：Request Method、Request URL、Request Headers、Request Body，即请求方式、请求链接、请求头、请求体。

#### Request Method

请求方式，请求方式常见的有两种类型，GET和POST。

我们在浏览器中直接输入一个URL并回车，这便发起了一个GET请求，请求的参数会直接包含到URL里，例如百度搜索Python，这就是一个GET请求，链接为：[https://www.baidu.com/s?wd=Python](https://www.baidu.com/s?wd=Python)，URL中包含了请求的参数信息，这里参数wd就是要搜寻的关键字。POST请求大多为表单提交发起，如一个登录表单，输入用户名密码，点击登录按钮，这通常会发起一个POST请求，其数据通常以Form Data即表单的形式传输，不会体现在URL中。

GET和POST请求方法有如下区别：
* GET方式请求中参数是包含在URL里面的，数据可以在URL中看到，而POST请求的URL不会包含这些数据，数据都是通过表单的形式传输，会包含在Request Body中。
* GET方式请求提交的数据最多只有1024字节，而POST方式没有限制。

所以一般来说，网站登录验证的时候，需要提交用户名密码，这里包含了敏感信息，使用GET方式请求的话密码就会暴露在URL里面，造成密码泄露，所以这里最好以POST方式发送。文件的上传时，由于文件内容比较大，也会选用POST方式。

我们平常遇到的绝大部分请求都是GET或POST请求，另外还有一些请求方式，如HEAD、PUT、DELETE、OPTIONS、CONNECT、TRACE，我们简单将其总结如下：

| 方法	| 描述 |
| --- | ---- |
| GET	| 请求指定的页面信息，并返回实体主体。|
| HEAD | 类似于GET请求，只不过返回的响应中没有具体的内容，用于获取报头。 |
| POST | 向指定资源提交数据进行处理请求，数据被包含在请求体中。| 
| PUT	| 从客户端向服务器传送的数据取代指定的文档的内容。 |
| DELETE | 请求服务器删除指定的页面。 |
| CONNECT | 	HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。 |
| OPTIONS	| 允许客户端查看服务器的性能。|
| TRACE	| 回显服务器收到的请求，主要用于测试或诊断。|

本表参考：[http://www.runoob.com/http/http-methods.html](http://www.runoob.com/http/http-methods.html)。

#### Request URL

顾名思义，就是请求的网址，即统一资源定位符，用URL可以唯一确定我们想请求的资源。

#### Request Headers

请求头，用来说明服务器要使用的附加信息，比较重要的信息有Cookie、Referer、User-Agent等，下面将一些常用的头信息说明如下：

* Accept，请求报头域，用于指定客户端可接受哪些类型的信息。
* Accept-Language，指定客户端可接受的语言类型。
* Accept-Encoding，指定客户端可接受的内容编码。
* Host，用于指定请求资源的主机IP和端口号，其内容为请求URL的原始服务器或网关的位置。从HTTP 1.1版本开始，Request必须包含此内容。
* Cookie，也常用复数形式Cookies，是网站为了辨别用户进行Session跟踪而储存在用户本地的数据。Cookies的主要功能就是维持当前访问会话，例如我们输入用户名密码登录了某个网站，登录成功之后服务器会用Session保存我们的登录状态信息，后面我们每次刷新或请求该站点的其他页面时会发现都是保持着登录状态的，在这里就是Cookies的功劳，Cookies里有信息标识了我们所对应的服务器的Session会话，每次浏览器在请求该站点的页面时都会在请求头中加上Cookies并将其发送给服务器，服务器通过Cookies识别出是我们自己，并且查出当前状态是登录的状态，所以返回的结果就是登录之后才能看到的网页内容。
* Referer，此内容用来标识这个请求是从哪个页面发过来的，服务器可以拿到这一信息并做相应的处理，如做来源统计、做防盗链处理等。
* User-Agent，简称UA，它是一个特殊字符串头，使得服务器能够识别客户使用的操作系统及版本、浏览器及版本等信息。在做爬虫时加上此信息可以伪装为浏览器，如果不加很可能会被识别出为爬虫。
* Content-Type，即Internet Media Type，互联网媒体类型，也叫做MIME类型，在Http协议消息头中，使用它来表示具体请求中的媒体类型信息。例如text/html代表HTML格式，image/gif代表GIF图片，application/json代表Json类型，更多对应关系可以查看此对照表：[http://tool.oschina.net/commons](http://tool.oschina.net/commons)。

因此，Request Headers是Request等重要组成部分，在写爬虫的时候大部分情况都需要设定Request Headers。

#### Request Body

即请求体，一般承载的内容是POST请求中的Form Data，即表单数据，而对于GET请求Request Body则为空。

例如在这里我登录GitHub时捕获到的Request和Response如下：

![](./assets/2017-08-19-23-47-17.jpg)

在登录之前我们填写了用户名和密码信息，提交时就这些内容就会以Form Data的形式提交给服务器，此时注意Request Headers中指定了Content-Type为application/x-www-form-urlencoded，只有设置Content-Type为application/x-www-form-urlencoded才会以Form Data形式提交，另外我们也可以将Content-Type设置为application/json来提交Json数据，或者设置为multipart/form-data来上传文件。

下面列出了Content-Type和POST提交数据方式的关系：

| Content-Type | 提交数据方式 |
| --- | ---- |
| application/x-www-form-urlencoded | Form表单提交 |
| multipart/form-data | 表单文件上传提交 |
| application/json | 序列化Json数据提交 |
| text/xml | XML数据提交 |

在爬虫中如果我们要构造POST请求需要注意这几种Content-Type，了解各种请求库的各个参数设置时使用的是哪种Content-Type，不然可能会导致POST提交后得不到正常的Response。

以上便是对Request各部分内容的解释。

### 6. Response

Response，即响应，由服务端返回给客户端。Response可以划分为三部分，Response Status Code、Response Headers、Response Body。

#### Response Status Code

响应状态码，此状态码表示了服务器的响应状态，如200则代表服务器正常响应，404则代表页面未找到，500则代表服务器内部发生错误。在爬虫中，我们可以根据状态码来判断服务器响应状态，如判断状态码为200，则证明成功返回数据，再进行进一步的处理，否则直接忽略。

下面用表格列出了常见的错误代码及错误原因：

| 状态码  | 说明        | 详情                                 |
| ---- | :-------- | :--------------------------------- |
| 100  | 继续        | 请求者应当继续提出请求。服务器已收到请求的一部分，正在等待其余部分。 |
| 101  | 切换协议      | 请求者已要求服务器切换协议，服务器已确认并准备切换。         |
| 200  | 成功        | 服务器已成功处理了请求。                       |
| 201  | 已创建       | 请求成功并且服务器创建了新的资源。                  |
| 202  | 已接受       | 服务器已接受请求，但尚未处理。                    |
| 203  | 非授权信息     | 服务器已成功处理了请求，但返回的信息可能来自另一来源。        |
| 204  | 无内容       | 服务器成功处理了请求，但没有返回任何内容。              |
| 205  | 重置内容      | 服务器成功处理了请求，内容被重置。                  |
| 206  | 部分内容      | 服务器成功处理了部分请求。                      |
| 300  | 多种选择      | 针对请求，服务器可执行多种操作。                   |
| 301  | 永久移动      | 请求的网页已永久移动到新位置，即永久重定向。             |
| 302  | 临时移动      | 请求的网页暂时跳转到其他页面，即暂时重定向。             |
| 303  | 查看其他位置    | 如果原来的请求是POST，重定向目标文档应该通过GET提取。     |
| 304  | 未修改       | 此次请求返回的网页未修改，继续使用上次的资源。            |
| 305  | 使用代理      | 请求者应该使用代理访问该网页。                    |
| 307  | 临时重定向     | 请求的资源临时从其他位置响应。                    |
| 400  | 错误请求      | 服务器无法解析该请求。                        |
| 401  | 未授权       | 请求没有进行身份验证或验证未通过。                  |
| 403  | 禁止访问      | 服务器拒绝此请求。                          |
| 404  | 未找到       | 服务器找不到请求的网页。                       |
| 405  | 方法禁用      | 服务器禁用了请求中指定的方法。                    |
| 406  | 不接受       | 无法使用请求的内容响应请求的网页。                  |
| 407  | 需要代理授权    | 请求者需要使用代理授权。                       |
| 408  | 请求超时      | 服务器请求超时。                           |
| 409  | 冲突        | 服务器在完成请求时发生冲突。                     |
| 410  | 已删除       | 请求的资源已永久删除。                        |
| 411  | 需要有效长度    | 服务器不接受不含有效内容长度标头字段的请求。             |
| 412  | 未满足前提条件   | 服务器未满足请求者在请求中设置的其中一个前提条件。          |
| 413  | 请求实体过大    | 请求实体过大，超出服务器的处理能力。                 |
| 414  | 请求URI过长   | 请求网址过长，服务器无法处理。                    |
| 415  | 不支持类型     | 请求的格式不受请求页面的支持。                    |
| 416  | 请求范围不符    | 页面无法提供请求的范围。                       |
| 417  | 未满足期望值    | 服务器未满足期望请求标头字段的要求。                 |
| 500  | 服务器内部错误   | 服务器遇到错误，无法完成请求。                    |
| 501  | 未实现       | 服务器不具备完成请求的功能。                     |
| 502  | 错误网关      | 服务器作为网关或代理，从上游服务器收到无效响应。           |
| 503  | 服务不可用     | 服务器目前无法使用。                         |
| 504  | 网关超时      | 服务器作为网关或代理，但是没有及时从上游服务器收到请求。       |
| 505  | HTTP版本不支持 | 服务器不支持请求中所用的 HTTP 协议版本。            |

#### Response Headers

响应头，其中包含了服务器对请求的应答信息，如Content-Type、Server、Set-Cookie等，下面将一些常用的头信息说明如下：

* Date，标识Response产生的时间。
* Last-Modified，指定资源的最后修改时间。
* Content-Encoding，指定Response内容的编码。
* Server，包含了服务器的信息，名称，版本号等。
* Content-Type，文档类型，指定了返回的数据类型是什么，如text/html则代表返回HTML文档，application/x-javascript则代表返回JavaScript文件，image/jpeg则代表返回了图片。
* Set-Cookie，设置Cookie，Response Headers中的Set-Cookie即告诉浏览器需要将此内容放在Cookies中，下次请求携带Cookies请求。
* Expires，指定Response的过期时间，使用它可以控制代理服务器或浏览器将内容更新到缓存中，如果再次访问时，直接从缓存中加载，降低服务器负载，缩短加载时间。

#### Resposne Body

即响应体，最重要的当属响应体内容了，响应的正文数据都是在响应体中，如请求一个网页，它的响应体就是网页的HTML代码，请求一张图片，它的响应体就是图片的二进制数据。所以最主要的数据都包含在响应体中了，我们做爬虫请求网页后要解析的内容就是解析响应体。

![](./assets/2017-06-08-02-07-42.jpg)

我们在浏览器开发者工具中点击Preview，就可以看到网页的源代码，这也就是响应体内容，是解析的目标。

我们在做爬虫时主要解析的内容就是Resposne Body，通过Resposne Body我们可以得到网页的源代码、Json数据等等，然后从中做相应内容的提取。

以上便是Response的组成部分。

### 7. 结语

本节我们了解了HTTP的基本原理，通过如上描述，我们应该对访问网页背后的请求和响应过程有了大体的认识，本节涉及到的知识点需要好好掌握，在后面分析网页请求的时候会经常用到。

