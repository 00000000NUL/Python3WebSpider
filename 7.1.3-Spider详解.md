### Spider详解

#### Spider运行流程

在实现Scrapy爬虫项目时，最核心的类便是Spider类了，它定义了如何爬取某个网站的流程和解析方式。简单来讲，Spider要做的事就是两类：

* 定义爬取网站的动作
* 分析爬取下来的网页

对于Spider类来说，整个爬取循环如下所述：

* 以初始的URL初始化Request，并设置回调函数。 当该Request成功请求并返回时，将生成Response，并作为参数传给该回调函数。
* 在回调函数内分析返回的网页内容。返回结果可以有两种形式，一种是解析到的有效结果返回字典或Item 对象。下一步可经过处理后(或直接)保存，另一种是解析得下一个(如下一页)链接，可以利用此链接构造Request并设置新的回调函数，返回Request。
* 如果返回的是字典或Item对象，可通过Feed Exports等形式存入到文件，如果设置了Pipeline的话，可以经由Pipeline处理（如过滤、修正等）并保存。
* 如果返回的是Reqeust，那么Request中设置的回调函数会得到响应结果Response，可以再次使用选择器(Selectors) 来分析新得到的网页内容，并根据分析的数据生成item。

通过以上几步循环往复进行，便完成了站点的爬取。

#### Spider类分析

在上一节的例子中我们定义的Spider是继承自`scrapy.spiders.Spider`，这个类是最简单最基本的Spider类，每个其他的Spider必须继承这个类，还有后文要说明的一些特殊Spider类也都是继承自它。

这个类里提供了start_requests方法的默认实现，读取并请求start_urls属性, 并根据返回的结果调用parse方法解析结果。另外它还有一些基础属性，下面对其进行讲解：

* name，爬虫名称

定义spider名字的字符串(string)。spider的名字定义了Scrapy如何定位(并初始化)spider，所以其必须是唯一的。 不过您可以生成多个相同的spider实例(instance)，这没有任何限制。 name是spider最重要的属性，而且是必须的。

如果该spider爬取单个网站(single domain)，一个常见的做法是以该网站(domain)(加或不加 后缀 )来命名spider。 例如，如果spider爬取 mywebsite.com ，该spider通常会被命名为 mywebsite 。



