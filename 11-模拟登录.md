# 模拟登录

在很多情况下，页面的某些信息需要登录才可以查看，对于爬虫来说，需要爬取的信息如果需要登录才可以看到的话，那么我们可能就需要做一些模拟登录的事情了。

在前面我们也了解了Session和Cookies的用法，简单来说，我们在浏览器上打开一个网页然后模拟登录之后，实际上是在客户端生成了Cookies，而Cookies里面保存了SessionID的信息，登录之后的后续请求都会携带生成后的Cookies发送给服务器，这样服务器就会根据Cookies判断出对应的SessionID，进而找到Session，如果判断当前Session是有效的，那么就判断用户当前已经登录了，返回请求的页面信息即可，这样我们就可以看到登录之后的页面了。

所以这其中的核心就是获取登录之后的Cookies，我们只要有了这个Cookies就可以用它来获取登录后的页面信息了。而要获取Cookies，我们可以手动在浏览器里面输入用户密码，然后再从浏览器里面把Cookies复制下来，但是这样做明显会增加人工工作量，爬虫的目的不就是自动化吗？所以我们要做的就是用程序来代替这个过程，也就是用程序来模拟登录。

所以本章我们来介绍一下模拟登录的相关方法以及怎样维护一个Cookies池。