# Spider Middleware的用法

Spider Middleware，介入到Scrapy的Spider处理机制的钩子框架，我们首先来看下它的架构：

![](./assets/2017-07-29-11-06-50.jpg)

可以发现当Downloader生成Response之后发送给Spider的过程中会经过Spider Middleware处理，当Spider处理生成Item和Request之后还会经过Spider Middleware的处理。

那也就是说Spider Middleware作用的位置就是以下三个：
* 在Downloader生成的Response发送给Spider之前，也就是我们可以在Response发送给Spider之前对Response进行处理。
* 在Spider生成的Request发送给Scheduler之前，也就是我们可以在Request发送给Scheduler之前对Request进行处理。
* 在Spider生成的Item发送给Item Pipeline之前，也就我们可以在Item发送给Item Pipeline之前对Item进行处理。

首先需要说明的是在Scrapy里其实已经提供了许多Spider Middleware，它们被SPIDER_MIDDLEWARES_BASE 这个变量所定义，

这个变量的内容如下：

```python
{
    'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware': 50,
    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': 500,
    'scrapy.spidermiddlewares.referer.RefererMiddleware': 700,
    'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware': 800,
    'scrapy.spidermiddlewares.depth.DepthMiddleware': 900,
}
```

和Downloader Middleware一样，要使用Spider Middleware首先要将其加入到SPIDER_MIDDLEWARES 设置中，该设置会和 Scrapy中 SPIDER_MIDDLEWARES_BASE  定义的Spider Middleware合并，然后根据优先级排序，最后得到一个有序列表。第一个 Middleware是最靠近引擎的，最后一个是 Middleware是最靠近Spider的。

## 核心方法

Scrapy内置的Spider Middleware为Scrapy提供了基础的功能，如果我们想要扩展其功能也十分简单，我们只需要实现某几个方法即可。

每个Spider Middleware都是定义了以下一个或多个方法的类，核心的四个方法是：
* process_spider_input(response, spider)
* process_spider_output(response, result, spider)
* process_spider_exception(response, exception, spider)
* process_start_requests(start_requests, spider)

我们只需要实现其中的至少一个方法就可以定义一个Spider Middleware，下面我们来看下这三个方法的详细用法。

### process_spider_input(response, spider)

当Response通过Spider Middleware时，该方法被调用，处理该Response。

方法的参数有两个：
* response (Response 对象) – 被处理的response
* spider (Spider 对象) – 该response对应的spider

process_spider_input() 应该返回 None 或者抛出一个异常。

* 如果其返回 None ，Scrapy将会继续处理该Response，调用所有其他的Spider Middleware直到Spider处理该Response。

* 如果其抛出一个异常(exception)，Scrapy将不会调用任何其他Spider Middleware的 process_spider_input() 方法，并调用request的errback。 errback的输出将会以另一个方向被重新输入到中间件中，使用 process_spider_output() 方法来处理，当其抛出异常时则调用 process_spider_exception() 来处理。

### process_spider_output(response, result, spider)

当Spider处理Response返回结果时，该方法被调用。

方法的参数有三个：
* response (Response 对象) – 生成该输出的Response
* result (包含 Request 或 Item 对象的可迭代对象) – spider返回的result
* spider (Spider 对象) – 其结果被处理的spider

process_spider_output() 必须返回包含 Request 或 Item 对象的可迭代对象(iterable)。

### process_spider_exception(response, exception, spider)

当Spider或 Spider Middleware的 process_spider_input() 方法抛出异常时， 该方法被调用。

方法的参数有三个：

* response (Response 对象) – 异常被抛出时被处理的Response
* exception (Exception 对象) – 被抛出的异常
* spider (Spider 对象) – 抛出该异常的Spider

process_spider_exception() 必须要么返回 None ， 要么返回一个包含 Response 或 Item 对象的可迭代对象(iterable)。

* 如果其返回 None ，Scrapy将继续处理该异常，调用Spider Middleware中的其他中间件的 process_spider_exception() 方法，直到所有Spider Middleware都被调用，该异常到达引擎(异常将被记录并被忽略)。
* 如果其返回一个可迭代对象，则中间件链的 process_spider_output() 方法被调用， 其他的 process_spider_exception() 将不会被调用。

### process_start_requests(start_requests, spider)

该方法以Spider启动的Request为参数被调用，执行的过程类似于 process_spider_output() ，只不过其没有相关联的Response并且必须返回Request。

方法的参数有两个：
start_requests (包含 Request 的可迭代对象) – Start Requests
spider (Spider 对象) – Start Requests所属的Spider

其必须返回另一个包含 Request 对象的可迭代对象。
