## 3.2.3 高级用法

在前面一节我们了解了Requests的基本用法，如基本的GET、POST请求以及Response对象的用法，本节我们再来了解下Requests的一些高级用法，如文件上传，代理设置，Cookies设置等等。

### 1. 文件上传

我们知道Reqeuests可以模拟提交一些数据，假如有的网站需要我们上传文件，我们同样可以利用它来上传，实现非常简单，实例如下：

```python
import requests

files = {'file': open('favicon.ico', 'rb')}
r = requests.post("http://httpbin.org/post", files=files)
print(r.text)
```

在上面一节中我们下载保存了一个文件叫做favicon.ico，这次我们用它为例来模拟文件上传的过程。需要注意的是，favicon.ico 这个文件需要和当前脚本在同一目录下。如果有其它文件，当然也可以使用其它文件来上传，更改下名称即可。

运行结果如下：

```json
{
  "args": {}, 
  "data": "", 
  "files": {
    "file": "data:application/octet-stream;base64,AAAAAA...="
  }, 
  "form": {}, 
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Content-Length": "6665", 
    "Content-Type": "multipart/form-data; boundary=809f80b1a2974132b133ade1a8e8e058", 
    "Host": "httpbin.org", 
    "User-Agent": "python-requests/2.10.0"
  }, 
  "json": null, 
  "origin": "60.207.237.16", 
  "url": "http://httpbin.org/post"
}
```

以上部分内容省略，这个网站会返回一个Response，里面包含files这个字段，而form是空的，这证明文件上传部分会单独有一个files字段来标识。

### 2. Cookies

在前面我们使用了Urllib处理过Cookies，写法比较复杂，而有了Requests，获取和设置 Cookies 只需要一步即可完成。

我们先用一个实例感受一下获取 Cookies 的过程：

```python
import requests

r = requests.get("https://www.baidu.com")
print(r.cookies)
for key, value in r.cookies.items():
    print(key + '=' + value)
```

运行结果如下：

```python
<RequestsCookieJar[<Cookie BDORZ=27315 for .baidu.com/>, <Cookie __bsi=13533594356813414194_00_14_N_N_2_0303_C02F_N_N_N_0 for .www.baidu.com/>]>
BDORZ=27315
__bsi=13533594356813414194_00_14_N_N_2_0303_C02F_N_N_N_0
```

首先我们调用了cookies属性即可成功得到了Cookies，可以发现它是一个RequestCookieJar类型，然后我们用items()方法将其转化为元组组成的列表，遍历输出每一个Cookie的名和值，实现Cookies的遍历解析。

当然，我们也可以直接用Cookies 来维持登录状态。

比如我们以知乎为例，直接利用 Cookies 来维持登录状态。

首先登录知乎，将Headers中的Cookies 复制下来，这里可以替换成你自己的Cookies。

![](/assets/3-2-4.png)

将其设置到Headers里面，发送Request，示例如下：

```python
import requests

headers = {
    'Cookie': 'q_c1=31653b264a074fc9a57816d1ea93ed8b|1474273938000|1474273938000; d_c0="AGDAs254kAqPTr6NW1U3XTLFzKhMPQ6H_nc=|1474273938"; __utmv=51854390.100-1|2=registration_date=20130902=1^3=entry_date=20130902=1;a_t="2.0AACAfbwdAAAXAAAAso0QWAAAgH28HQAAAGDAs254kAoXAAAAYQJVTQ4FCVgA360us8BAklzLYNEHUd6kmHtRQX5a6hiZxKCynnycerLQ3gIkoJLOCQ==";z_c0=Mi4wQUFDQWZid2RBQUFBWU1DemJuaVFDaGNBQUFCaEFsVk5EZ1VKV0FEZnJTNnp3RUNTWE10ZzBRZFIzcVNZZTFGQmZn|1474887858|64b4d4234a21de774c42c837fe0b672fdb5763b0',
    'Host': 'www.zhihu.com',
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36',
}
r = requests.get("http://www.zhihu.com", headers=headers)
print(r.text)
```

发现结果中包含了正常的登录信息，包含了用户名信息，如图所示：

![](/assets/3-2-5.png)

证明登录成功。

当然也可以通过cookies参数来设置，不过这样就需要构造RequestsCookieJar对象，而且需要分割一下Cookie变量，相对繁琐，不过效果是相同的，实例如下：

```python
import requests

cookies = 'q_c1=31653b264a074fc9a57816d1ea93ed8b|1474273938000|1474273938000; d_c0="AGDAs254kAqPTr6NW1U3XTLFzKhMPQ6H_nc=|1474273938"; __utmv=51854390.100-1|2=registration_date=20130902=1^3=entry_date=20130902=1;a_t="2.0AACAfbwdAAAXAAAAso0QWAAAgH28HQAAAGDAs254kAoXAAAAYQJVTQ4FCVgA360us8BAklzLYNEHUd6kmHtRQX5a6hiZxKCynnycerLQ3gIkoJLOCQ==";z_c0=Mi4wQUFDQWZid2RBQUFBWU1DemJuaVFDaGNBQUFCaEFsVk5EZ1VKV0FEZnJTNnp3RUNTWE10ZzBRZFIzcVNZZTFGQmZn|1474887858|64b4d4234a21de774c42c837fe0b672fdb5763b0'
jar = requests.cookies.RequestsCookieJar()
headers = {
    'Host': 'www.zhihu.com',
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36'
}
for cookie in cookies.split(';'):
    key, value = cookie.split('=', 1)
    jar.set(key, value)
r = requests.get("http://www.zhihu.com", cookies=jar, headers=headers)
print(r.text)
```

上面我们首先新建了一个RequestCookieJar对象，然后将复制下来的Cookies利用split()方法分割，利用set()方法设置好每一个Cookie的key和value，然后通过调用Requests的get()方法并传递给cookies参数即可，当然由于知乎本身的限制，headers参数也不能少，只不过不需要在原来的headers参数里面设置Cookie字段了。

测试后，发现同样可以正常登录知乎。

### 3. 会话维持

在Requests中，我们如果直接利用get()或post()等方法的确可以做到模拟网页的请求。但是这实际上是相当于不同的会话，即不同的Session，也就是说相当于你用了两个浏览器打开了不同的页面。

设想这样一个场景，我们第一个请求利用了post()方法登录了某个网站，第二次想获取成功登录后的自己的个人信息，你又用了一次get()方法去请求个人信息页面。实际上，这相当于打开了两个浏览器，是两个完全不相关的会话，能成功获取个人信息吗？那当然不能。

有小伙伴可能就说了，我在两次请求的时候都设置好一样的Cookies不就行了？可以，但这样做起来还是显得很繁琐，我们还有更简单的解决方法。

其实解决这个问题的主要方法就是维持同一个会话，也就是相当于打开一个新的浏览器选项卡而不是新开一个浏览器。但是我又不想每次设置Cookies，那该怎么办？这时候就有了新的利器Session对象。

利用它，我们可以方便地维护一个会话，而且不用担心Cookies的问题，它会帮我们自动处理好。

下面用一个实例来感受一下：

```python
import requests

requests.get('http://httpbin.org/cookies/set/number/123456789')
r = requests.get('http://httpbin.org/cookies')
print(r.text)
```

在实例中我们请求了一个测试网址，[http://httpbin.org/cookies/set/number/123456789](http://httpbin.org/cookies/set/number/123456789)，请求这个网址我们可以设置一个Cookie，名称叫做number，内容是123456789，随后又请求了[http://httpbin.org/cookies](http://httpbin.org/cookies)，此网址可以获取当前的Cookie。

这样能成功获取到设置的Cookie吗？试试看。

运行结果如下：

```python
{
  "cookies": {}
}
```

并不行。我们再用Session试试看：

```python
import requests

s = requests.Session()
s.get('http://httpbin.org/cookies/set/number/123456789')
r = s.get('http://httpbin.org/cookies')
print(r.text)
```

看下运行结果：

```python
{
  "cookies": {
    "number": "123456789"
  }
}
```

成功获取！这下能体会到同一个会话和不同会话的区别了吧？

所以，利用Session我们可以做到模拟同一个会话，而且不用担心Cookies的问题，通常用于模拟登录成功之后再进行下一步的操作。

Session在平常用到的非常广泛，可以用于模拟在一个浏览器中打开同一站点的不同页面，在后文会有专门的章节来讲解这部分内容。

### 4. SSL证书验证

Requests 提供了证书验证的功能，当发送HTTP请求的时候，它会检查SSL证书，我们可以使用`verify`这个参数来控制是否检查此证书，其实如果不加的话默认是True，会自动验证。

在前面我们提到过12306的证书实际上是不被官方认可的，会出现证书验证错误的结果，现在我们试着用Requests来请求一下12306来看下结果。

我们现在访问它都可以看到一个证书问题的页面，如图所示：

![](/assets/3-2-6.png)

现在我们用Requests来测试一下：

```python
import requests

response = requests.get('https://www.12306.cn')
print(response.status_code)
```

运行结果如下：

```python
requests.exceptions.SSLError: ("bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)",)
```

提示一个错误，叫做 SSLError，证书验证错误。所以如果我们请求一个HTTPS站点，但是证书验证错误的页面时，就会报这样的错误，那么如何避免这个错误呢？很简单，把 verify 这个参数设置为False 即可。

改成如下代码：

```python
import requests

response = requests.get('https://www.12306.cn', verify=False)
print(response.status_code)
```

这样，就会打印出请求成功的状态码。

```python
/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:852: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)
200
```

不过发现报了一个警告，它提示建议让我们给它指定证书。

我们可以通过设置忽略警告的方式来屏蔽这个警告：

```python
import requests
from requests.packages import urllib3

urllib3.disable_warnings()
response = requests.get('https://www.12306.cn', verify=False)
print(response.status_code)
```

或者通过捕获警告到日志的方式忽略警告：

```python
import logging
import requests
logging.captureWarnings(True)
response = requests.get('https://www.12306.cn', verify=False)
print(response.status_code)
```

当然我们也可以指定一个本地证书用作客户端证书，可以是单个文件（包含密钥和证书）或一个包含两个文件路径的元组。

```python
import requests

response = requests.get('https://www.12306.cn', cert=('/path/server.crt', '/path/key'))
print(response.status_code)
```

当然上面代码是实例，我们需要有crt和key文件，指定它们的路径。注意本地私有证书的key必须要是解密状态，加密状态的key是不支持的。

### 5. 代理设置

对于某些网站，在测试的时候请求几次，能正常获取内容。但是一旦开始大规模爬取，对于大规模且频繁的请求，网站可能会直接登录验证，验证码，甚至直接把IP给封禁掉。

那么为了防止这种情况的发生，我们就需要设置代理来解决这个问题，在Requests中需要用到 proxies 这个参数。

可以用这样的方式设置：

```python
import requests

proxies = {
  "http": "http://10.10.1.10:3128",
  "https": "http://10.10.1.10:1080",
}

requests.get("https://www.taobao.com", proxies=proxies)
```

当然直接运行这个实例可能不行，因为这个代理可能是无效的，请换成自己的有效代理试验一下。

若代理需要使用 HTTP Basic Auth，可以使用类似http://user:password@host:port 这样的语法来设置代理。

实例如下：

```python
import requests

proxies = {
    "http": "http://user:password@10.10.1.10:3128/",
}
requests.get("https://www.taobao.com", proxies=proxies)
```

除了基本的HTTP代理，Requests还支持SOCKS协议的代理。

首先需要安装 socks 这个库。

```
pip3 install 'requests[socks]'
```

然后就可以使用SOCKS协议代理了，实例如下：

```python
import requests

proxies = {
    'http': 'socks5://user:password@host:port',
    'https': 'socks5://user:password@host:port'
}
requests.get("https://www.taobao.com", proxies=proxies)
```

### 6. 超时设置

在本机网络状况不好或者服务器网络响应太慢甚至无响应时，我们可能会等待特别久的时间才可能会收到一个响应，甚至到最后收不到响应而报错。为了防止服务器不能及时响应，我们应该设置一个超时时间，即超过了这个时间还没有得到响应，那就报错。

设置超时时间需要用到 timeout参数。这个时间的计算是发出 Request 到服务器返回 Response 的时间。

下面用一个实例来感受一下：

```python
import requests

r = requests.get("https://www.taobao.com", timeout = 1)
print(r.status_code)
```

通过这样的方式，我们可以将超时时间设置为 1 秒，如果 1 秒内没有响应，那就抛出异常。

实际上请求分为两个阶段，即connect（连接）和read（读取）。

上面的设置 timeout 值将会用作 connect 和 read 二者的 timeout 总和。

如果要分别指定，就可以传入一个元组：

```python
r = requests.get('https://www.taobao.com', timeout=(5,11, 30))
```

如果想永久等待，那么我们可以直接将 timeout 设置为None，或者不设置直接留空，因为默认是None。这样的话，如果服务器还在运行，但是响应特别慢，那就慢慢等吧，它永远不会返回超时错误的。

用法如下：

```python
r = requests.get('https://www.taobao.com', timeout=None)
```

或直接不加参数：

```python
r = requests.get('https://www.taobao.com')
```

### 7. 身份认证

在访问网站时，我们可能会遇到这样的认证页面：

![](./assets/2017-08-20-11-16-25.jpg)

如果遇到这样的网站验证，可以使用Requests自带的身份认证功能，实例如下：

```python
import requests
from requests.auth import HTTPBasicAuth

r = requests.get('http://localhost:5000', auth=HTTPBasicAuth('username', 'password'))
print(r.status_code)
```

如果用户名和密码正确的话，请求时就会自动认证成功，会返回200状态码，如果认证失败，则会返回401状态码。

当然如果参数都传一个HTTPBasicAuth类，就显得有点繁琐了，所以Requests 提供了一个更简单的写法，可以直接传一个元组，它会默认使用 HTTPBasicAuth 这个类来认证。

所以上面的代码可以直接简写如下：

```python
import requests

r = requests.get('http://localhost:5000', auth=('username', 'password'))
print(r.status_code)
```

运行效果和上面的是一样的。

Requests 还提供了其他的认证方式，如OAuth认证，不过需要安装oauth包，命令如下：

```
pip3 install requests_oauthlib
```

使用OAuth1认证的方法如下：

```python
import requests
from requests_oauthlib import OAuth1

url = 'https://api.twitter.com/1.1/account/verify_credentials.json'
auth = OAuth1('YOUR_APP_KEY', 'YOUR_APP_SECRET',
              'USER_OAUTH_TOKEN', 'USER_OAUTH_TOKEN_SECRET')
requests.get(url, auth=auth)
```

更多详细的功能就可以参考 requests_oauthlib 的官方文档：[https://requests-oauthlib.readthedocs.org/](https://requests-oauthlib.readthedocs.org/)，在此就不再赘述了。

### 8. Prepared Request

在前面介绍Urllib时我们可以将Request表示为一个数据结构，Request的各个参数都可以通过一个Request对象来表示，在Requests里面同样可以做到，这个数据结构就叫Prepared Request。

我们用一个实例感受一下：

```python
from requests import Request, Session

url = 'http://httpbin.org/post'
data = {
    'name': 'germey'
}
headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36'
}
s = Session()
req = Request('POST', url, data=data, headers=headers)
prepped = s.prepare_request(req)
r = s.send(prepped)
print(r.text)
```

在这里我们引入了 Request，然后用url、data、headers参数构造了一个Request对象，这时我们需要再调用Session的prepare_request将其转换为一个Prepared Request对象，然后调用send()方法发送即可，运行结果如下：

```json
{
  "args": {}, 
  "data": "", 
  "files": {}, 
  "form": {
    "name": "germey"
  }, 
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Connection": "close", 
    "Content-Length": "11", 
    "Content-Type": "application/x-www-form-urlencoded", 
    "Host": "httpbin.org", 
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36"
  }, 
  "json": null, 
  "origin": "182.32.203.166", 
  "url": "http://httpbin.org/post"
}
```

可以看到我们达到了同样的POST请求效果。

有了Request这个对象，我们就可以将一个个请求当做一个独立的对象来看待，这样在进行队列调度的时候会非常方便，后面我们会有一节使用它来构造一个Request队列。

### 9. 结语

本节讲解了Requests的一些高级用法，这些用法在后面实战部分会经常用到，需要熟练掌握。

更多的用法可以参考Requests的官方文档：[http://docs.python-requests.org/](http://docs.python-requests.org/)。