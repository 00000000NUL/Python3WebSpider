# 13.6 Spider Middleware的用法

Spider Middleware是介入到Scrapy的Spider处理机制的钩子框架。我们首先来看看它的架构，如图13-1所示。

当Downloader生成Response之后，Response会被发送给Spider，在发送给Spider之前，Response会首先经过Spider Middleware处理，当Spider处理生成Item和Request之后，Item和Request还会经过Spider Middleware的处理。

Spider Middleware有如下三个作用。

* 我们可以在Downloader生成的Response发送给Spider之前，也就是在Response发送给Spider之前对Response进行处理。

* 我们可以在Spider生成的Request发送给Scheduler之前，也就是在Request发送给Scheduler之前对Request进行处理。

* 我们可以在Spider生成的Item发送给Item Pipeline之前，也就是在Item发送给Item Pipeline之前对Item进行处理。

### 1. 使用说明

需要说明的是，Scrapy其实已经提供了许多Spider Middleware，它们被SPIDER_MIDDLEWARES_BASE这个变量所定义。

SPIDER_MIDDLEWARES_BASE变量的内容如下：

```python
{
    'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware': 50,
    'scrapy.spidermiddlewares.offsite.OffsiteMiddleware': 500,
    'scrapy.spidermiddlewares.referer.RefererMiddleware': 700,
    'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware': 800,
    'scrapy.spidermiddlewares.depth.DepthMiddleware': 900,
}
```

和Downloader Middleware一样，Spider Middleware首先加入到SPIDER_MIDDLEWARES设置中，该设置会和Scrapy中SPIDER_MIDDLEWARES_BASE定义的Spider Middleware合并。然后根据键值的数字优先级排序，得到一个有序列表。第一个Middleware是最靠近引擎的，最后一个Middleware是最靠近Spider的。

### 2. 核心方法

Scrapy内置的Spider Middleware为Scrapy提供了基础的功能。如果我们想要扩展其功能，只需要实现某几个方法即可。

每个Spider Middleware都定义了以下一个或多个方法的类，核心方法有如下4个。

* process_spider_input(response, spider)
* process_spider_output(response, result, spider)
* process_spider_exception(response, exception, spider)
* process_start_requests(start_requests, spider)

只需要实现其中一个方法就可以定义一个 Spider Middleware。下面我们来看看这4个方法的详细用法。

#### process_spider_input(response, spider)

当 Response 通过 Spider Middleware 时，该方法被调用，处理该 Response。

方法的参数有两个：
* response，即 Response 对象，即被处理的 Response
* spider，即 Spider 对象，即该 response 对应的 Spider

process_spider_input() 应该返回 None 或者抛出一个异常。

* 如果其返回 None ，Scrapy 将会继续处理该 Response，调用所有其他的 Spider Middleware 直到 Spider 处理该 Response。

* 如果其抛出一个异常，Scrapy 将不会调用任何其他 Spider Middlewar e的 process_spider_input() 方法，并调用 Request的 errback() 方法。 errback 的输出将会以另一个方向被重新输入到中间件中，使用 process_spider_output() 方法来处理，当其抛出异常时则调用 process_spider_exception() 来处理。

#### process_spider_output(response, result, spider)

当 Spider 处理 Response 返回结果时，该方法被调用。

方法的参数有三个：
* response，即Response 对象，即生成该输出的 Response
* result，包含 Request 或 Item 对象的可迭代对象，即 Spider 返回的结果
* spider，即Spider 对象，即其结果对应的Spider

process_spider_output() 必须返回包含 Request 或 Item 对象的可迭代对象。

#### process_spider_exception(response, exception, spider)

当 Spider 或 Spider Middleware 的 process_spider_input() 方法抛出异常时， 该方法被调用。

方法的参数有三个：

* response，即 Response 对象，即异常被抛出时被处理的Response
* exception，即 Exception 对象，被抛出的异常
* spider，即 Spider 对象，即抛出该异常的 Spider

process_spider_exception() 必须要么返回 None ， 要么返回一个包含 Response 或 Item 对象的可迭代对象。

* 如果其返回 None ，Scrapy 将继续处理该异常，调用其他 Spider Middleware 中的 process_spider_exception() 方法，直到所有 Spider Middleware 都被调用。
* 如果其返回一个可迭代对象，则其他 Spider Middleware 的 process_spider_output() 方法被调用， 其他的 process_spider_exception() 将不会被调用。

#### process_start_requests(start_requests, spider)

该方法以 Spider 启动的 Request 为参数被调用，执行的过程类似于 process_spider_output() ，只不过其没有相关联的 Response 并且必须返回 Request。

方法的参数有两个：
* start_requests，即包含 Request 的可迭代对象，即 Start Requests
* spider，即Spider 对象，即 Start Requests 所属的 Spider

其必须返回另一个包含 Request 对象的可迭代对象。

### 3. 结语

本节介绍了Spider Middleware的基本原理和自定义Spider Middleware的方法。Spider Middleware使用的频率不如Downloader Middleware的高，在必要的情况下它可以用来方便数据的处理。
